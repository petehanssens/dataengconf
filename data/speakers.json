[
  {
    "name": "Zhamak Dehghani",
    "role": "speaker",
    "id": "zhamak-dehghani",
    "image": "/images/speakers/zhamak-dehghani.jpg",
    "linkedin": "https://www.linkedin.com/in/zhamak-dehghani/",
    "title": "Introduction to Data Mesh: A Paradigm Shift in Data Platform Architecture",
    "description": "Zhamak Dehghani introduces Data Mesh, the next generation analytical data platform, that shifts to a paradigm drawing from modern distributed architecture considering domains as the first class concern, applying platform thinking to create self-serve data infrastructure, and treating data as a product. Zhamak compares data mesh to the prior big data analytics architectures, and provides some insights into how to implement this architecture in your organization.",
    "bio": "Zhamak Dehghani is the director of emerging technologies at ThoughtWorks North America and a member of various tech advisory boards. Her focus is on technologies and architectures that by nature decentralize decision making and ultimately power. Her recent work involves applying distributed computing principles to big data management and decentralized digital identity to build in security in distributed systems.",
    "tagLine": "Director of emerging technologies - ThoughtWorks North America",
    "link": "/speaker/zhamak-dehghani",
    "Day": "Thursday",
    "StartTime": "14:10",
    "SessionNumber": "01"
  },
  {
    "name": "Gian Merlino",
    "role": "speaker",
    "id": "gian-merlino",
    "image": "/images/speakers/Gian_Merlino.png",
    "linkedin": "https://www.linkedin.com/in/gianmerlino/",
    "title": "Some Like It Hot",
    "description": "Today's world has no shortage of systems that claim to help with analysis of large amounts of data. Under the hood, today's popular systems have a variety of interesting and unique architectures. In this talk, we'll reflect on why you can never seem to find that single perfect system, and how to think about their capabilities on a spectrum.",
    "bio": "Gian is a co-founder and CTO of Imply. Gian is also one of the main committers of Druid. Previously, Gian led the data ingestion team at Metamarkets and held senior engineering positions at Yahoo. He holds a B.S. in Computer Science from Caltech.",
    "tagLine": "Co-Founder & CTO at Imply",
    "link": "/speaker/gian-merlino",
    "Day": "Friday",
    "StartTime": "09:10",
    "SessionNumber": "10"
  },
  {
    "name": "Aiko Klostermann",
    "role": "speaker",
    "id": "aiko-klostermann",
    "image": "/images/speakers/aiko-klostermann.jpg",
    "linkedin": "https://www.linkedin.com/in/aikoklostermann/",
    "title": "Artificial Intelligence? - more like Artificial Stupsidity!",
    "description": "Nowadays ‚ÄúArtificial Intelligence‚Äù is everywhere! And rightly so, it does enable us to do really cool things, things we couldn‚Äôt even imagine doing just a decade ago. In fact, it sometimes just feels like magic. This ‚Äòmagic‚Äô behind it is often powered by ‚ÄúMachine Learning‚Äù. But even ‚ÄúAI‚Äù has its limitations.\r\nI‚Äôll show examples where ‚ÄúAI‚Äù and ML have failed (sometimes with horrible consequences) and will explain why failures are unavosidable in ML but also mention what we can do to reduce them in the future.\r\nFurthermore, I‚Äôll showcase how current AI implementations discriminate against minorities and how that in some cases even leads to a higher risk of death for those groups.\r\nI‚Äôll cover the bias that humans introduce and I‚Äôll explain how poor choice of data makes our world even more unjust than it already is.\r\n\r\nThe takeaway for the audience: AI can fail and sometimes it has horrible consequences. Why is AI so hard to ‚Äúdo right‚Äù? How can we make AI better?",
    "bio": "Aiko works as a consultant and developer for ThoughtWorks.\r\nHe is passionate about data science, software craftsmanship, clean code, and infrastructure engineering. While working with clients he focusses on improving the development process and code quality of the teams he's working with.\r\n\r\nNowadays working in Singapore, Aiko has previously worked with clients in Germany, the UK and India as well. He leveraged Artificial Intelligence to help clients gain a competitive advantage. Recently his focus moved onto infrastructure development for building (data) platforms to better enable client teams.",
    "tagLine": "Technology Consultant, Problemsolver & Troublemaker @ Thoughtworks",
    "link": "/speaker/aiko-klostermann",
    "Day": "Friday",
    "StartTime": "12:20",
    "SessionNumber": "16"
  },
  {
    "name": "Yana Segal",
    "role": "speaker",
    "id": "yana-segal",
    "image": "/images/speakers/Yana_Segal.jpeg",
    "linkedin": "https://www.linkedin.com/in/yana-segal-605379bb/",
    "title": "Automating ML pipelines with Kubernetes and Airflow",
    "description": "Recently our team has started automating our ML engineering pipelines to move from a tedious, hours long and manual procedure to a state of the art Kubernetes-based automated pipeline that places you one click away from a trained and deployed ML model. \r\nMoving from manual deployment to Kubernetes scalable and versatile environment enabled us to add multiple features that were out of reach in the manual deployment such as autoscaling (ASG), log monitoring (ELK stack) and process visibility (Grafana). Additionally, to automatically trigger our pipeline we used Airflow that produced its own series of advantages and challenges. \r\nWe believe the issues we encountered during the process represent valuables lessons. In this talk, we'll share these lessons with you, to help you in your journey towards automating ML pipelines.  \r\nTopics include:\r\n* Autoscaling in Kubernetes\r\n* Visibility and logging stacks in Kubernetes\r\n* ML pipelines scheduling with Airflow ",
    "bio": "Data and ML Engineer at Nielsen, with versatile hands on experience deploying ETLs and ML pipelines using technologies like python and Spark in the cloud environment. Recent enthusiast of Go.",
    "tagLine": "ML Engineer at Nielsen",
    "link": "/speaker/yana-segal",
    "Day": "Thursday",
    "StartTime": "17:20",
    "SessionNumber": "07"
  },
  {
    "name": "Dom Colyer",
    "role": "speaker",
    "id": "dom-colyer",
    "image": "/images/speakers/dom-coyler.jpg",
    "linkedin": "https://www.linkedin.com/in/dominic-colyer/",
    "title": "Building a Code Generated Data Platform",
    "description": "Speed, Speed, Speed! This talk will explore using tools to dramatically improve the speed of building a data platform.  Fivetran will land the data in Snowflake from disparate sources. Then, using automatic SQL code generation views, tables and tasks will be built to move the data into a designated history area that can service a wside range of analytical use cases.",
    "bio": "A passionate cloud data architect I love optimising things with automation and code generation.",
    "tagLine": "Sales Engineer, Fivetran ",
    "link": "/speaker/dom-colyer",
    "Day": "Thursday",
    "StartTime": "13:20",
    "SessionNumber": "03"
  },
  {
    "name": "Robin Moffatt",
    "role": "speaker",
    "id": "robin-moffatt",
    "image": "/images/speakers/robbin-moffatt2.jpg",
    "linkedin": "https://www.linkedin.com/in/robinmoffatt/",
    "title": "ü§ñBuilding a Telegram bot with Apache Kafka and ksqlDB",
    "description": "Imagine you‚Äôve got a stream of data; it‚Äôs not ‚Äúbig data,‚Äù but it‚Äôs certainly a lot. Within the data, you‚Äôve got some bits you‚Äôre interested in, and of those bits, you‚Äôd like to be able to query information about them at any point. Sounds fun, right? Since I mentioned ‚Äúquerying,‚Äù I‚Äôd hazard a guess that you‚Äôve got in mind an additional datastore of some sort, whether relational or NoSQL.\r\n\r\nBut what if I told you...that you dsidn‚Äôt need any datastore other than Kafka itself? What if you could ingest, filter, enrich, aggregate, and query data with just Kafka? With ksqlDB we can do just this, and I want to show you exactly how.\r\n\r\nIn this hands-on talk we'll walk through an example of building a Telegram bot in which ksqlDB provsides the key/value lookups driven by a materialised view on the stream of events in Kafka. We'll take a look at what ksqlDB is and its capabilities for processing data and driving applications, as well as integrating with other systems. ",
    "bio": "Robin is a Senior Developer Advocate at Confluent, the company founded by the original creators of Apache Kafka, as well as an Oracle ACE Director (Alumnus). He has been speaking at conferences since 2009 including QCon, Devoxx, Strata, Kafka Summit, and √òredev. You can find many of his talks online at http://rmoff.net/talks/, and his blog articles at http://cnfl.io/rmoff and http://rmoff.net/.",
    "tagLine": "Senior Developer Advocate at Confluent",
    "link": "/speaker/robin-moffatt",
    "Day": "Thursday",
    "StartTime": "18:20",
    "SessionNumber": "09"
  },
  {
    "name": "Kerry McRae",
    "role": "speaker",
    "id": "kerry-mcrae",
    "image": "/images/speakers/kerry_mcrae.jpeg",
    "linkedin": "https://www.linkedin.com/in/kerry-mcrae-59042227/",
    "title": "Building data integration services for real-time on AWS",
    "description": "For many use cases timing is critical and the value of data diminishes rapsidly. This means that every micro-second counts. In this session, learn how we provside customers with fully managed streaming options, enabling data to be collected, stored and processed as soon as it is created. Find out how to decside which of the services are best suited to your needs so you can derive insights in seconds or minutes instead of hours or days.",
    "bio": "",
    "tagLine": "Solutions Architect at Amazon Web Services",
    "link": "/speaker/kerry-mcrae",
    "Day": "Friday",
    "StartTime": "13:20",
    "SessionNumber": "18"
  },
  {
    "name": "Marta Paes Moreira",
    "role": "speaker",
    "id": "marta-paes-moreira",
    "image": "/images/speakers/marta-paes.jpg",
    "linkedin": "https://www.linkedin.com/in/morsapaes/",
    "title": "Change Data Capture with Flink SQL and Debezium",
    "description": "Change Data Capture (CDC) has become the standard to capture and propagate committed changes from a database to downstream consumers, for example to keep multiple datastores in sync and avosid common pitfalls such as dual writes (remember? \"Friends don't let friends do dual writes\"). \r\n\r\nConsuming these changelogs with Apache Flink used to be a pain, but the latest release (Flink 1.11) introduced not only support for CDC, but support for CDC from the comfort of your SQL couch. In this talk, we'll demo how to use Flink SQL to easily process database changelog data generated with Debezium.",
    "bio": "Marta is a Developer Advocate at Ververica (formerly data Artisans) and a contributor to Apache Flink. After finding her mojo in open source, she is committed to making sense of Data Engineering through the eyes of those using its by-products. Marta holds a Master‚Äôs in Biomedical Engineering, where she developed a particular taste for multi-dimensional data visualization, and previously worked as a Data Warehouse Engineer at Zalando and Accenture.",
    "tagLine": "Developer Advocate at Ververica",
    "link": "/speaker/marta-paes-moreira",
    "Day": "Thursday",
    "StartTime": "17:50",
    "SessionNumber": "08"
  },
  {
    "name": "Mike Gouline",
    "role": "speaker",
    "id": "mike-gouline",
    "image": "/images/speakers/mike-gouline.jpg",
    "linkedin": "https://www.linkedin.com/in/gouline/",
    "title": "Data Team as an Optimisation Problem",
    "description": "Many (if not most) companies reach a point when data becomes a priority. This implies building out an internal practice to integrate into existing systems and processes to deliver the sought insights. In a field so wside, relatively recent and infamous for its buzzwords-per-second count, formalising problems and making explainable decisions is the only route that won‚Äôt see you run out of resources and people‚Äôs patience.\r\n\r\nThis talk explores how we approached this challenge at mx51 armed with lessons from engineering and statistics. We start by defining the optimisation problem formally(-ish) and then applying it to actual decisions faced along the way, including technology selection, ETL, warehousing, visualisation and ML-driven insights.\r\n\r\nThe content is reasonably technical on engineering and architecture topics, but it does not go into actual statistical modelling of the optimisation problem too heavily.",
    "bio": "Software engineer with over 10 years of industry experience. Moving around between enterprise and startups, mobile and backend, one \"pivot\" later I landed in data. Currently leading the data practice at mx51, building out the platform from scratch and educating the company about what \"data\" really means.",
    "tagLine": "Data Architect at mx51",
    "link": "/speaker/mike-gouline",
    "Day": "Thursday",
    "StartTime": "16:50",
    "SessionNumber": "06"
  },
  {
    "name": "Charles Feddersen",
    "role": "speaker",
    "id": "charles-feddersen",
    "image": "/images/speakers/charles_feddersen.jpg",
    "linkedin": "https://www.linkedin.com/in/charles-feddersen-66186b25/",
    "title": "Developing end-to-end analytics solutions with the latest Azure Synapse features",
    "description": "In this demo-rich session we‚Äôll develop an end-to-end Azure Synapse Analytics solution, a limitless analytics service that brings together enterprise data warehousing and Big Data analytics, that features the latest data integration, big data, and data warehousing capabilities at scale. ",
    "bio": "Charles is one of the Group Program Managers for Azure Synapse Analytics based in Redmond in the US and works with customers globally in support of modernizing their enterprise analytics platforms to Azure.",
    "tagLine": "Principal Group Program Manager at Microsoft",
    "link": "/speaker/charles-feddersen",
    "Day": "Thursday",
    "StartTime": "14:50",
    "SessionNumber": "02"
  },
  {
    "name": "Atif Shaikh",
    "role": "speaker",
    "id": "atif-shaikh",
    "image": "/images/speakers/atif-shaikh.jpg",
    "linkedin": "https://www.linkedin.com/in/datamantiq/",
    "title": "Enabling HTAP capabilities in your existing data platform(s)",
    "description": "Hybrsid Transactional-Analytical Processing (HTAP) combines the power of OLTP and OLAP systems and provsides a unified engine for transactions, analytics and AI. \r\n\r\nThis talk will sidentify architectural patterns and technology enablers that you can introduce to your existing (or new) data platform(s) to brsidge some critical gaps between operations of the business and outputs from the data platform(s). \r\n\r\nTakeaway some sideas on how to serve customers ‚Äòin the moment‚Äô of their needs through this capability. ",
    "bio": "Atif is an independent consultant specialising in DataOps and data literacy (change management) programs. He has 15+ years of experience across BI, analytics, data engineering and data science roles with a mix of both startups and more mature organisations across 4 continents.",
    "tagLine": "Principal at Datamantiq",
    "link": "/speaker/atif-shaikh",
    "Day": "Friday",
    "StartTime": "12:50",
    "SessionNumber": "17"
  },
  {
    "name": "Joel Roland",
    "role": "speaker",
    "id": "joel-roland",
    "image": "./images/speakers/joel_roland.jpg",
    "linkedin": "https://www.linkedin.com/in/joel-roland/",
    "title": "ETL and Data Ingestion Made Easy",
    "description": "Organisations have a wealth of information siloed in various data sources. These could vary from databases (Oracle, MySQL, Postgres, etc) to product applications (Salesforce, Marketo, HubSpot, etc). A significant number use cases need data from these diverse data sources to produce meaningful reports and predictions. \r\n\r\nFor many years, organisations tried to centrally collect all their data in the data warehouse but these were not suited or were expensive for handling unstructured data, semi-structured data, and data with high variety, velocity, and volume. It also limited the types of analytics data teams could use; unable to do machine learning or anything more than basic SQL.\r\n\r\nDelta Lake, released and open-sourced by Databricks in 2019, is helping thousands of organisations build central data repositories in an open format much more reliably and efficiently than before. Delta Lake on Databricks provides Acid transactions and efficient indexing that is critical for exposing the data for various access patterns, ranging from ad-hoc SQL queries in BI tools, to scheduled ML jobs. \r\n\r\nThis session will provide the one-two step of Data Ingestion & Quality made easy with Databricks, which includes Steve Lee, guest presenter from Atlassian, who will talk about how their data team tackles compliance and regulations (GDPR, CCPA) and their approach to self-service data ingestion.",
    "bio": "Joel Roland is the Solutions Architect Manager for Databricks Australia and New Zealand. His role is to help customers' translate their business requirements and use cases into technical solutions that run on the Databricks platform. Joel has over 15 years experience working in IT, with over 10 years in Data & Analytics. Prior to joining Databricks, Joel he held various Data & Analytic roles in organisations such as Cloudera, CSC (DXC) and the University of Wollongong",
    "tagLine": "Solution Architecture Manager at Databricks",
    "link": "/speaker/joel-roland",
    "Day": "Friday",
    "StartTime": "10:50",
    "SessionNumber": "13"
  },
  {
    "name": "Steve Lee",
    "role": "speaker",
    "id": "steve-lee",
    "image": "./images/speakers/steve_lee.jpeg",
    "title": "ETL and Data Ingestion Made Easy",
    "description": "Organisations have a wealth of information siloed in various data sources. These could vary from databases (Oracle, MySQL, Postgres, etc) to product applications (Salesforce, Marketo, HubSpot, etc). A significant number use cases need data from these diverse data sources to produce meaningful reports and predictions. \r\n\r\nFor many years, organisations tried to centrally collect all their data in the data warehouse but these were not suited or were expensive for handling unstructured data, semi-structured data, and data with high variety, velocity, and volume. It also limited the types of analytics data teams could use; unable to do machine learning or anything more than basic SQL.\r\n\r\nDelta Lake, released and open-sourced by Databricks in 2019, is helping thousands of organisations build central data repositories in an open format much more reliably and efficiently than before. Delta Lake on Databricks provides Acid transactions and efficient indexing that is critical for exposing the data for various access patterns, ranging from ad-hoc SQL queries in BI tools, to scheduled ML jobs. \r\n\r\nThis session will provide the one-two step of Data Ingestion & Quality made easy with Databricks, which includes Steve Lee, guest presenter from Atlassian, who will talk about how their data team tackles compliance and regulations (GDPR, CCPA) and their approach to self-service data ingestion.",
    "bio": "",
    "tagLine": "Principal Data Engineer at Atlassian",
    "link": "/speaker/steve-lee",
    "Day": "Friday",
    "StartTime": "10:50",
    "SessionNumber": "13"
  },
  {
    "name": "Vidya Venugopal",
    "role": "speaker",
    "id": "vidya-venugopal",
    "image": "/images/speakers/vidya-venugopal.jpg",
    "linkedin": "https://www.linkedin.com/in/vidya-venugopal-27660019/",
    "title": "Ever changing data model - Schema management for the future",
    "description": "Schema means different things, depending upon your role in IT. If you are a data analyst, schema relates to tables, or it means REST API Specification for a web developer, or Schema registry if you are using streaming technologies like Kafka. Regardless, Schemas ensure data quality, it helps introduce a contract between parties who want to share data between each other be it developers or applications. \r\n\r\nIn the beginning of the talk, let's compare how schema management has evolved over a period of time. How contracts are established using schemas, how it ensures data quality, how it helps you manage changes within or between organisations. \r\n\r\nFurther, lets particularly focus on Event Streaming.How changes can be managed in the world of fast moving data. Every event in your organisation needs a specification, It is as important as defining a REST API Spec or a Table schema. How to seamlessly manage these changes between your consumers and producers ? And what are the technology options we have? ",
    "bio": "Vidya is a software engineer and the founder of thekafkanerd.io. She has years of experience developing integration applications for a variety of enterprises. Her area of expertise includes Distributed systems, Enterprise Integration & Event Streaming. She is currently working as a senior developer with Vanguard Australia.",
    "tagLine": "Senior Developer at Vanguard",
    "link": "/speaker/vidya-venugopal",
    "Day": "Thursday",
    "StartTime": "15:50",
    "SessionNumber": "04"
  },
  {
    "name": "Mike Del Balso",
    "role": "speaker",
    "id": "mike-del-balso",
    "image": "/images/speakers/Mike_Del_Balso.jpg",
    "linkedin": "https://www.linkedin.com/in/michaeldelbalso/",
    "title": "Feature Stores",
    "description": "First pioneered in the Michelangelo platform at Uber, Feature Stores have been core components of the ML stacks of some of the largest tech companies for many years. Today, they are emerging as key components of the production ML stack across the industry. In this talk, we introduce the Tecton Feature Store, discuss the problems it solves, and show how Feature Stores solve many of the core data engineering challenges teams face when putting ML into production today.",
    "bio": "Co-Founder + CEO of Tecton, Creator of Uber Michelangelo, ex-PM of ML for ads at Google",
    "tagLine": "Co-Founder & CEO at Tecton",
    "link": "/speaker/mike-del-balso",
    "Day": "Friday",
    "StartTime": "10:20",
    "SessionNumber": "12"
  },
  {
    "name": "Sam Harley",
    "role": "speaker",
    "id": "sam-harley",
    "image": "/images/speakers/sam_harley.jpeg",
    "linkedin": "https://www.linkedin.com/in/samharley/",
    "title": "How MongoDB Enables Real-Time Data with Event-Driven Architecture",
    "description": "Sam Harley, Senior Solutions Architect at MongoDB, will discuss why event-driven architectures are the natural evolution of how the world stores and accesses data, and show how MongoDB can assist in establishing an event-driven architecture using the MongoDB Kafka Connector.",
    "bio": "Sam is a Senior Solutions Architect with MongoDB and is based in Sydney. Sam has worked in the IT industry for fifteen years and is recognised as a trusted advisor to customers throughout Australia, providing best-practice advice to assist in designing and building reliable and scalable solutions using MongoDB.",
    "tagLine": "Senior Solutions Architect at MongoDB",
    "link": "/speaker/sam-harley",
    "Day": "Friday",
    "StartTime": "11:20",
    "SessionNumber": "14"
  },
  {
    "name": "Larene Le Gassick",
    "role": "speaker",
    "id": "larene-le-gassick",
    "image": "/images/speakers/larene-legassic.JPEG",
    "linkedin": "https://www.linkedin.com/in/larene/",
    "title": "Inclusive Storytelling with Data",
    "description": "Ever wondered how to design a bar graph for people who can't see? \r\n\r\nThe truth is, building data visualisations with accessibility in mind makes data more accessible and easier to understand for everyone ‚Äî not just those with disabilities.\r\n\r\nIn this session, Larene will share a bunch of tips and examples to help you share your awesome data with the world!",
    "bio": "Software engineer, Meetup organiser, Microsoft MVP, ex-consultant, ex-computer vision engineer, ex-robotics. Speaks and tweets about accessibility.",
    "tagLine": "Engineer at Datalust",
    "link": "/speaker/larene-le-gassick",
    "Day": "Friday",
    "StartTime": "11:50",
    "SessionNumber": "15"
  },
  {
    "name": "Louis Lee",
    "role": "speaker",
    "id": "louis-lee",
    "image": "/images/speakers/louis_lee.jpg",
    "linkedin": "https://www.linkedin.com/in/louis-lee-8859b32/",
    "title": "Snowflake Cloud Data Platform - Building a Governed Data Lake",
    "description": "Organisations, regardless of market or mission must manage data, minimise data risk, and meet data-focused regulatory compliance mandates. Snowflake‚Äôs cloud data platform from the very beginning - with a multitude of features like encrypting data in transit and at rest, secure views, secure functions, RBAC, continuous data protection etc. - has allowed you to build a well governed data lake. \r\nA Data Lake often also involves bringing data from external parties to complement your enterprise data. That makes data sharing crucial to business operations. Unlike cloud storage and file sharing services, Snowflake Data Sharing enables immediate querying of data in a secure, governed and controlled environment.",
    "bio": "Louis is passionate about data analytics and associated technologies. He is a member of the Sales Engineering team in Snowflake helping customers to find meaningful insights from vast amount of data that we collect every day. Louis has 20 years of experience in the information technology industry, of which 15 years with Hyperion and Oracle. He has solid experience in software development, consulting and has supported customers across APAC. Louis holds a degree in Computer Science and a Masters in Communication Design from Queensland University of Technology.  ",
    "tagLine": "Senior Sales Engineer at Snowflake",
    "link": "/speaker/louis-lee",
    "Day": "Thursday",
    "StartTime": "16:20",
    "SessionNumber": "05"
  },
  {
    "name": "Caito Scherr",
    "role": "speaker",
    "id": "caito-scherr",
    "image": "/images/speakers/caito-scherr.jpg",
    "linkedin": "https://www.linkedin.com/in/caito-scherr-80aa09b6/",
    "title": "Sweet Streams are Made of These: data-driven development in stream processing",
    "description": "How do you use data-driven development tactics to leverage the strengths of stream processing? This talk will cover aspects of data-driven development in the context of building streaming systems, using successes and failures of some real world examples, specifically with Apache Beam and Apache Flink. ",
    "bio": "Caito is a software engineer in Portland, Oregon who most recently worked on New Relic's main stream processing team. She has presented about this work at various meetups and conferences (in the US and Europe). Outsside of tech, she loves running, woodworking, and terrible puns.",
    "tagLine": "Data Analytics, Stream Processing, and Terrible Puns",
    "link": "/speaker/caito-scherr",
    "Day": "Friday",
    "StartTime": "09:50",
    "SessionNumber": "11"
  }
]
